/root/Codes/part3/rnn/data.py:358: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  tensor_data = torch.load(f'{input_dir}/tensor_data.pt')
tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,
          0.0000e+00,  1.0000e+00],
        [ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,
          1.1548e-04,  1.0000e+00],
        [ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,
          2.3096e-04,  1.0000e+00],
        ...,
        [ 9.0179e-01, -4.3218e-01,  8.4488e-01,  ...,  9.9998e-01,
          5.3120e-03,  9.9999e-01],
        [ 1.2357e-01, -9.9234e-01,  1.3992e-01,  ...,  9.9998e-01,
          5.4274e-03,  9.9999e-01],
        [-7.6825e-01, -6.4014e-01, -6.6357e-01,  ...,  9.9998e-01,
          5.5429e-03,  9.9998e-01]])
Parameters: 4.33M
LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(49, 128)
    (layers): ModuleList(
      (0-11): 12 x LlamaDecoderLayer(
        (self_attn): LlamaSdpaAttention(
          (q_proj): Linear(in_features=128, out_features=512, bias=False)
          (k_proj): Linear(in_features=128, out_features=512, bias=False)
          (v_proj): Linear(in_features=128, out_features=512, bias=False)
          (o_proj): Linear(in_features=512, out_features=128, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=128, out_features=256, bias=False)
          (up_proj): Linear(in_features=128, out_features=256, bias=False)
          (down_proj): Linear(in_features=256, out_features=128, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm((128,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((128,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((128,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=128, out_features=49, bias=False)
)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 13.66it/s]
Initial | val loss: 24.23471541404724 | val acc: 0.0
start training
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 16.03it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.89it/s]
Step 0 | Train loss | 24.15688705444336 | Samples 0 | Train acc: 0.0 | Val loss: 24.23471541404724 | Val acc: 0.0 | learning rate: 3.846153846153846e-06
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.86it/s]
Step 782 | Train loss | 2.9174600867019302 | Samples 100096 | Train acc: 0.0 | Val loss: 1.8447804391384124 | Val acc: 0.0 | learning rate: 0.0002990288263900567
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.89it/s]
Step 1563 | Train loss | 0.6433046758556 | Samples 200064 | Train acc: 0.0074723911651728555 | Val loss: 0.49563789591193197 | Val acc: 0.0548 | learning rate: 0.00029570127048704877
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.92it/s]
Step 2344 | Train loss | 0.07981948128450654 | Samples 300032 | Train acc: 0.21656930217669654 | Val loss: 0.12069103140383959 | Val acc: 0.3608 | learning rate: 0.00029005890029289914
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.85it/s]
Step 3125 | Train loss | 0.019574797175400394 | Samples 400000 | Train acc: 0.4956085947503201 | Val loss: 0.05267688408493996 | Val acc: 0.5928 | learning rate: 0.0002821913583969805
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 16.42it/s]
Step 3907 | Train loss | 0.009394449502145805 | Samples 500096 | Train acc: 0.6304647538363172 | Val loss: 0.03847608934156597 | Val acc: 0.6734 | learning rate: 0.0002722095948580161
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.87it/s]
Step 4688 | Train loss | 0.005665044966623533 | Samples 600064 | Train acc: 0.7105373719590269 | Val loss: 0.03258983111009002 | Val acc: 0.7174 | learning rate: 0.00026029768893862337
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.82it/s]
Step 5469 | Train loss | 0.0037073366762814834 | Samples 700032 | Train acc: 0.7655249679897568 | Val loss: 0.03394743739627302 | Val acc: 0.7014 | learning rate: 0.00024663343957169893
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:02<00:00, 15.92it/s]
Step 6250 | Train loss | 0.0025393575776461942 | Samples 800000 | Train acc: 0.8072883322663252 | Val loss: 0.015574248833581805 | Val acc: 0.8432 | learning rate: 0.00023143393614573303
 40%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                                                             | 7813/19531 [22:58<34:26,  5.67it/s]
Step 7032 | Train loss | 0.001982452836775956 | Samples 900096 | Train acc: 0.8305027173913043 | Val loss: 0.013765967101790011 | Val acc: 0.8598 | learning rate: 0.0002149188218693342
